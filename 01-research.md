---
layout: page
title: Research
permalink: research.html
---

- [Finding an HRI Partner in a Crowd](#finding-an-hri-partner-in-a-crowd) 
- [Selecting and Commanding a Subset of a Group of Robots](#selecting-and-commanding-a-subset-of-a-group-of-robots)
- [A Robust Integrated System for Selecting and Commanding Multiple Mobile Robots](#a-robust-integrated-system-for-selecting-and-commanding-multiple-mobile-robots)

## Finding an HRI partner in a crowd

### Summery

We present a probabilistic framework for multimodal information fusion to address the detection of the most promising interaction partner among a group of people, in an uncontrolled environment. To achieve robust operation, the system integrates three multi-modal percepts of humans and regulates robot’ behaviour to approach the location with the highest probability of an engaged human. A series of real-world experiments demon- strates the robustness and practicality of the proposed system for controlling robot’s attention.

### Demo

<div class="grid grid-pad">

    <div class="col-1-1">
       <div class="content">
           <iframe width="560" height="315" src="https://www.youtube.com/embed/PLB6OQWqaUs" frameborder="0" allowfullscreen></iframe>
       </div>
    </div>

</div>  

<hr>


## Selecting and commanding a subset of a group of robots

### Summery

We present a multimodal system for creating, modifying and commanding groups of robots from a population. Extending our previous work on selecting an individual robot from a population by face engagement, we show that we can dynamically create groups of a desired number of robots by speaking the number we desire, e.g. “You three”, and looking at the robots we intend to form the group. We evaluate two different methods of detecting which robots are intended by the user, and show that an iterated election performs well in our setting. We also show that teams can be modified by adding and removing individual robots: “And you. Not you”. The success of the system is examined for different spatial configurations of robots with respect to each other and the user to find the proper workspace of selection methods.

### Demo

<div class="grid grid-pad">

    <div class="col-1-1">
       <div class="content">
           <iframe width="560" height="315" src="https://www.youtube.com/embed/I8sJud-OApw" frameborder="0" allowfullscreen></iframe>
       </div>
    </div>
</div> 

<div class="grid grid-pad">

    <div class="col-1-1">
       <div class="content">
           <iframe width="560" height="315" src="https://www.youtube.com/embed/heiYPVGFnEM" frameborder="0" allowfullscreen></iframe>
       </div>
    </div>
</div> 

<hr>

## A Robust integrated system for selecting and commanding multiple mobile robots

### Summery

We describe a system whereby multiple humans and mobile robots interact robustly using a combination of sensing and signalling modalities. Extending our previous work on selecting an individual robot from a population by face-engagement, we show that reaching toward a robot - a specialization of pointing - can be used to designate a particular robot for subsequent one-on-one interaction. To achieve robust operation despite frequent sensing problems, the robots use three phases of human detection and tracking, and emit audio cues to solicit interaction and guide the behaviour of the human. A series of real-world trials demonstrates the practicality of our approach.

### Demo

<div class="grid grid-pad">

    <div class="col-1-1">
       <div class="content">
            <iframe width="560" height="315" src="https://www.youtube.com/embed/WLwb7gJOl8w" frameborder="0" allowfullscreen></iframe>
       </div>
</div>
